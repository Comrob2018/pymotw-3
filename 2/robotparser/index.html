<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>robotparser &#8211; Internet spider access control - Python Module of the Week</title>

<link rel="stylesheet" href="../_static/default.css" 
    type="text/css" />
<style>
    body {
        margin: 8px;
    }
    .highlight {
        background-color: white;
        border: 0;
    }
    .highlight pre {
        background-color: white;
    }
</style>

<link href="../_static/css/leaves.css" rel="stylesheet" type="text/css" />
<link rel="alternate" type="application/atom+xml"
      title="Doug Hellmann"
      href="http://feeds.feedburner.com/DougHellmann" />
<link rel="alternate" type="application/atom+xml"
      title="Doug Hellmann Project Releases"
      href="http://feeds.feedburner.com/DougHellmann-Releases" />
<link rel="alternate" type="application/atom+xml"
      title="Doug Hellmann Links"
      href="http://feeds.feedburner.com/DougHellmannLinkBlog" />



<script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
      URL_ROOT:    '../',
      VERSION:     '1.133',
      COLLAPSE_MODINDEX: false,
      FILE_SUFFIX: '.html'
  };
</script>

<script type="text/javascript" src="../_static/jquery.js"></script>
<script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="contents" title="Global table of contents" href="../contents.html" />
    <link rel="index" title="Global index" href="../genindex.html" />
    <link rel="top" title="Python Module of the Week" href="../index.html" />
    <link rel="up" title="File Formats" href="../file_formats.html" />
    <link rel="next" title="Cryptographic Services" href="../cryptographic.html" />
    <link rel="prev" title="ConfigParser – Work with configuration files" href="../ConfigParser/index.html" />

<meta name="verify-v1" content="5saTcOa2HLac4V85yUg3SARfun1PqT5Upu7IR/6fpv4="/>
</head>
<body>
    
<div id="container">
    
<div id="header">
  <a href="/"><h1>PyMOTW</h1></a>
  <p></p>
</div>

<div id="sidebar_left_wrapper">

<div id="navigation"> 
	<ul id="navlist">
		<li><a href="../index.html">Home</a></li>
		<li><a href="https://doughellmann.com/" target="_">Blog</a></li>
		<li><a href="https://doughellmann.com/python-standard-library-by-example">The Book</a></li>
		<li><a href="../about.html">About</a></li>
		<li><a href="/2/genindex.html">Site Index</a></li>
	</ul>
</div>


  <div id="sidebar_left">
      <p>If you find this information useful, consider picking up a copy of my book,
      <i><a href="http://doughellmann.com/python-standard-library-by-example">The Python Standard Library By
      Example</a></i>.</p>
  </div>

</div>


<div id="sidebar">
  <h3>Page Contents</h3>
  <ul>
<li><a class="reference internal" href="#">robotparser &#8211; Internet spider access control</a><ul>
<li><a class="reference internal" href="#robots-txt">robots.txt</a></li>
<li><a class="reference internal" href="#simple-example">Simple Example</a></li>
<li><a class="reference internal" href="#long-lived-spiders">Long-lived Spiders</a></li>
</ul>
</li>
</ul>
    <h3>Navigation</h3>
      <p>
    <a href="../contents.html"><strong>Table of Contents</strong></a><br/>
    
          <a href="../ConfigParser/index.html" title="previous chapter"><strong>Previous:</strong> ConfigParser &#8211; Work with configuration files</a><br/>
          <a href="../cryptographic.html" title="next chapter"><strong>Next:</strong> Cryptographic Services</a><br/>
      </p>
    
      <h3>This Page</h3>
      <p>
      <a href="../_sources/robotparser/index.txt"
               rel="nofollow">Show Source</a>
      </p><h3>Examples</h3>

<p>The output from all the example programs from PyMOTW has been
generated with Python 2.7.8, unless otherwise noted. Some
of the features described here may not be available in earlier
versions of Python.</p>

<p>If you are looking for examples that work under Python 3, please
refer to the <a href="/3/">PyMOTW-3</a> section of the site.</p><p><a target="new" href="https://doughellmann.com/blog/the-python-3-standard-library-by-example/"><img src="../_static/images/py3-book-cover.jpg"><br>Now available for Python 3!</a></p>
<p><a target="new" href="https://doughellmann.com/blog/the-python-standard-library-by-example/"><img src="../_static/images/py2-book-cover.jpg"><br>Buy the book!</a></p>
</div>


<div id="content">

    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../cryptographic.html" title="Cryptographic Services"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../ConfigParser/index.html" title="ConfigParser – Work with configuration files"
             accesskey="P">previous</a> |</li>
        <li><a href="../contents.html">PyMOTW</a> &raquo;</li>
          <li><a href="../file_formats.html" accesskey="U">File Formats</a> &raquo;</li> 
      </ul>
    </div>

  <div class="section" id="module-robotparser">
<span id="robotparser-internet-spider-access-control"></span><h1>robotparser &#8211; Internet spider access control<a class="headerlink" href="#module-robotparser" title="Permalink to this headline">¶</a></h1>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Purpose:</th><td class="field-body">Parse robots.txt file used to control Internet spiders</td>
</tr>
<tr class="field-even field"><th class="field-name">Available In:</th><td class="field-body">2.1.3 and later</td>
</tr>
</tbody>
</table>
<p><a class="reference internal" href="#module-robotparser" title="robotparser: Internet spider access control"><tt class="xref py py-mod docutils literal"><span class="pre">robotparser</span></tt></a> implements a parser for the <tt class="docutils literal"><span class="pre">robots.txt</span></tt> file format, including a simple function for checking if a given user agent can access a resource.  It is intended for use in well-behaved spiders or other crawler applications that need to either be throttled or otherwise restricted.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The <a class="reference internal" href="#module-robotparser" title="robotparser: Internet spider access control"><tt class="xref py py-mod docutils literal"><span class="pre">robotparser</span></tt></a> module has been renamed <tt class="xref py py-mod docutils literal"><span class="pre">urllib.robotparser</span></tt> in Python 3.0.
Existing code using <a class="reference internal" href="#module-robotparser" title="robotparser: Internet spider access control"><tt class="xref py py-mod docutils literal"><span class="pre">robotparser</span></tt></a> can be updated using 2to3.</p>
</div>
<div class="section" id="robots-txt">
<h2>robots.txt<a class="headerlink" href="#robots-txt" title="Permalink to this headline">¶</a></h2>
<p>The <tt class="docutils literal"><span class="pre">robots.txt</span></tt> file format is a simple text-based access control system for computer programs that automatically access web resources (&#8220;spiders&#8221;, &#8220;crawlers&#8221;, etc.).  The file is made up of records that specify the user agent identifier for the program followed by a list of URLs (or URL prefixes) the agent may not access.</p>
<p>This is the <tt class="docutils literal"><span class="pre">robots.txt</span></tt> file for <tt class="docutils literal"><span class="pre">http://www.doughellmann.com/</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre>User-agent: *
Disallow: /admin/
Disallow: /downloads/
Disallow: /media/
Disallow: /static/
Disallow: /codehosting/
</pre></div>
</div>
<p>It prevents access to some of the expensive parts of my site that would overload the server if a search engine tried to index them.  For a more complete set of examples, refer to <a class="reference external" href="http://www.robotstxt.org/orig.html">The Web Robots Page</a>.</p>
</div>
<div class="section" id="simple-example">
<h2>Simple Example<a class="headerlink" href="#simple-example" title="Permalink to this headline">¶</a></h2>
<p>Using the data above, a simple crawler can test whether it is allowed to download a page using the <tt class="docutils literal"><span class="pre">RobotFileParser</span></tt>&#8216;s <tt class="docutils literal"><span class="pre">can_fetch()</span></tt> method.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">robotparser</span>
<span class="kn">import</span> <span class="nn">urlparse</span>

<span class="n">AGENT_NAME</span> <span class="o">=</span> <span class="s">&#39;PyMOTW&#39;</span>
<span class="n">URL_BASE</span> <span class="o">=</span> <span class="s">&#39;http://www.doughellmann.com/&#39;</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">robotparser</span><span class="o">.</span><span class="n">RobotFileParser</span><span class="p">()</span>
<span class="n">parser</span><span class="o">.</span><span class="n">set_url</span><span class="p">(</span><span class="n">urlparse</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">URL_BASE</span><span class="p">,</span> <span class="s">&#39;robots.txt&#39;</span><span class="p">))</span>
<span class="n">parser</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">PATHS</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">&#39;/&#39;</span><span class="p">,</span>
    <span class="s">&#39;/PyMOTW/&#39;</span><span class="p">,</span>
    <span class="s">&#39;/admin/&#39;</span><span class="p">,</span>
    <span class="s">&#39;/downloads/PyMOTW-1.92.tar.gz&#39;</span><span class="p">,</span>
    <span class="p">]</span>

<span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">PATHS</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">&#39;</span><span class="si">%6s</span><span class="s"> : </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">parser</span><span class="o">.</span><span class="n">can_fetch</span><span class="p">(</span><span class="n">AGENT_NAME</span><span class="p">,</span> <span class="n">path</span><span class="p">),</span> <span class="n">path</span><span class="p">)</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">urlparse</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">URL_BASE</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
    <span class="k">print</span> <span class="s">&#39;</span><span class="si">%6s</span><span class="s"> : </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">parser</span><span class="o">.</span><span class="n">can_fetch</span><span class="p">(</span><span class="n">AGENT_NAME</span><span class="p">,</span> <span class="n">url</span><span class="p">),</span> <span class="n">url</span><span class="p">)</span>
    <span class="k">print</span>
</pre></div>
</div>
<p>The URL argument to <tt class="docutils literal"><span class="pre">can_fetch()</span></tt> can be a path relative to the root of the site, or full URL.</p>
<div class="highlight-python"><div class="highlight"><pre>$ python robotparser_simple.py

  True : /
  True : http://www.doughellmann.com/

  True : /PyMOTW/
  True : http://www.doughellmann.com/PyMOTW/

  True : /admin/
  True : http://www.doughellmann.com/admin/

 False : /downloads/PyMOTW-1.92.tar.gz
 False : http://www.doughellmann.com/downloads/PyMOTW-1.92.tar.gz
</pre></div>
</div>
</div>
<div class="section" id="long-lived-spiders">
<h2>Long-lived Spiders<a class="headerlink" href="#long-lived-spiders" title="Permalink to this headline">¶</a></h2>
<p>An application that takes a long time to process the resources it downloads or that is throttled to pause between downloads may want to check for new <tt class="docutils literal"><span class="pre">robots.txt</span></tt> files periodically based on the age of the content it has downloaded already.  The age is not managed automatically, but there are convenience methods to make tracking it easier.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">robotparser</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">urlparse</span>

<span class="n">AGENT_NAME</span> <span class="o">=</span> <span class="s">&#39;PyMOTW&#39;</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">robotparser</span><span class="o">.</span><span class="n">RobotFileParser</span><span class="p">()</span>
<span class="c"># Using the local copy</span>
<span class="n">parser</span><span class="o">.</span><span class="n">set_url</span><span class="p">(</span><span class="s">&#39;robots.txt&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">parser</span><span class="o">.</span><span class="n">modified</span><span class="p">()</span>

<span class="n">PATHS</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">&#39;/&#39;</span><span class="p">,</span>
    <span class="s">&#39;/PyMOTW/&#39;</span><span class="p">,</span>
    <span class="s">&#39;/admin/&#39;</span><span class="p">,</span>
    <span class="s">&#39;/downloads/PyMOTW-1.92.tar.gz&#39;</span><span class="p">,</span>
    <span class="p">]</span>

<span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">path</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">PATHS</span><span class="p">):</span>
    <span class="k">print</span>
    <span class="n">age</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">parser</span><span class="o">.</span><span class="n">mtime</span><span class="p">())</span>
    <span class="k">print</span> <span class="s">&#39;age:&#39;</span><span class="p">,</span> <span class="n">age</span><span class="p">,</span>
    <span class="k">if</span> <span class="n">age</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">print</span> <span class="s">&#39;re-reading robots.txt&#39;</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">parser</span><span class="o">.</span><span class="n">modified</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span>
    <span class="k">print</span> <span class="s">&#39;</span><span class="si">%6s</span><span class="s"> : </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">parser</span><span class="o">.</span><span class="n">can_fetch</span><span class="p">(</span><span class="n">AGENT_NAME</span><span class="p">,</span> <span class="n">path</span><span class="p">),</span> <span class="n">path</span><span class="p">)</span>
    <span class="c"># Simulate a delay in processing</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>This extreme example downloads a new <tt class="docutils literal"><span class="pre">robots.txt</span></tt> file if the one it has is more than 1 second old.</p>
<div class="highlight-python"><div class="highlight"><pre>$ python robotparser_longlived.py


age: 0
  True : /

age: 1
  True : /PyMOTW/

age: 2 re-reading robots.txt
 False : /admin/

age: 1
 False : /downloads/PyMOTW-1.92.tar.gz
</pre></div>
</div>
<p>A &#8220;nicer&#8221; version of the long-lived application might request the modification time for the file before downloading the entire thing.  On the other hand, <tt class="docutils literal"><span class="pre">robots.txt</span></tt> files are usually fairly small, so it isn&#8217;t that much more expensive to just grab the entire document again.</p>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><a class="reference external" href="http://docs.python.org/2.7/library/robotparser.html">robotparser</a></dt>
<dd>The standard library documentation for this module.</dd>
<dt><a class="reference external" href="http://www.robotstxt.org/orig.html">The Web Robots Page</a></dt>
<dd>Description of robots.txt format.</dd>
</dl>
</div>
</div>
</div>


    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../cryptographic.html" title="Cryptographic Services"
             >next</a> |</li>
        <li class="right" >
          <a href="../ConfigParser/index.html" title="ConfigParser – Work with configuration files"
             >previous</a> |</li>
        <li><a href="../contents.html">PyMOTW</a> &raquo;</li>
          <li><a href="../file_formats.html" >File Formats</a> &raquo;</li> 
      </ul>
    </div>


</div>

<div id="footer">
 
<p>
    &copy; Copyright <a rel="author" href="../about.html">Doug Hellmann</a>.
    | <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/us/" rel="license"><img alt="Creative Commons License" style="border-width:0; align: center;" width="80" height="15" src="http://i.creativecommons.org/l/by-nc-sa/3.0/us/80x15.png"/></a>
    | Last updated on Jul 11, 2020.
   | Created using <a href="http://sphinx.pocoo.org/">Sphinx</a>.
   | Design based on "Leaves" by <a href="http://smallpark.org">SmallPark</a>
   | <a href="http://www.dreamhost.com/r.cgi?1246820/green.cgi?pymotw.com">
<img border="0" alt="Green Web Hosting! This site hosted by DreamHost."
src="https://secure.newdream.net/green4.gif" height="15" width="80" /></a></p>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-38546875-1', 'pymotw.com');
  ga('send', 'pageview');

</script>


</div>

</div>

</body>
</html>